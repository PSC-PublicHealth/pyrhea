{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "from collections import defaultdict\n",
    "import textwrap\n",
    "import tools_util as tu\n",
    "import pyrheautils\n",
    "import os.path\n",
    "import yaml\n",
    "from typebase import CareTier, PatientOverallHealth, DiagClassA\n",
    "import phacsl.utils.formats.csv_tools as csv_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utility Routines ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addTransfersToTable(srcFN, srcSchema, tbl=None):\n",
    "    if tbl is None:\n",
    "        tbl = {}\n",
    "    #print 'Importing the weight data file %s' % srcFN\n",
    "    pairsSeen = set()\n",
    "    rawTbl = pyrheautils.importConstants(pyrheautils.pathTranslate(srcFN), srcSchema)\n",
    "    for srcName, rec in rawTbl.items():\n",
    "        if srcName not in tbl:\n",
    "            tbl[srcName] = {}\n",
    "        for destName, ct in rec.items():\n",
    "            if (srcName, destName) in pairsSeen:\n",
    "                raise RuntimeError('Duplicate weight table entries for %s -> %s' %\n",
    "                                    (srcName, destName))\n",
    "            else:\n",
    "                pairsSeen.add((srcName, destName))\n",
    "                tbl[srcName][destName] = float(ct)\n",
    "    return tbl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recsToDict(recL, lblKey):\n",
    "    rslt = {}\n",
    "    for rec in recL:\n",
    "        newR = {}\n",
    "        recKey = rec[lblKey]\n",
    "        for key, val in rec.items():\n",
    "            if key != lblKey:\n",
    "                if key.startswith('To_'):\n",
    "                    newR[key[3:]] = val\n",
    "        rslt[recKey] = newR\n",
    "    return rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanTransferTbl(tbl, fnForMsg, obsoleteNameD):\n",
    "    inToOutD = defaultdict(lambda: 0)\n",
    "    outToInD = defaultdict(lambda: 0)\n",
    "    cleanedTbl = {}\n",
    "    for src, rec in tbl.items():\n",
    "        if src in obsoleteNameD:\n",
    "            if obsoleteNameD[src] in tbl:\n",
    "                print 'Src entries for both %s and %s in %s' % (src, obsoleteNameD[src], fnForMsg)\n",
    "                continue\n",
    "            print 'replacing src %s with new name %s'\n",
    "            src = obsoleteNameD[src]\n",
    "\n",
    "        if src in excludedFacDict:\n",
    "            for dst, ct in rec.items():\n",
    "                if dst in obsoleteNameD:\n",
    "                    if obsoleteNameD[dst] in rec:\n",
    "                        print 'Dst entries for both %s and %s in %s' % (src, obsoleteNameD[src], fnForMsg)\n",
    "                        continue\n",
    "                    print 'replacing %s with new name %s'\n",
    "                    dst = obsoleteNameD[dst]\n",
    "                if dst in facDict:\n",
    "                    outToInD[dst] += ct\n",
    "                    #print 'out to in: %s -> %s %s' % (src, dst, ct)\n",
    "        else:\n",
    "            assert src in facDict or src == 'COMMUNITY', 'unknown src %s in %s' % (src, fnForMsg)\n",
    "            cleanedTbl[src] = {}\n",
    "            for dst, ct in rec.items():\n",
    "                if dst in obsoleteNameD:\n",
    "                    if obsoleteNameD[dst] in rec:\n",
    "                        print 'Dst entries for both %s and %s in %s' % (src, obsoleteNameD[src], fnForMsg)\n",
    "                        continue\n",
    "                    print 'replacing dst %s with new name %s'\n",
    "                    dst = obsoleteNameD[dst]\n",
    "                if dst in excludedFacDict:\n",
    "                    #print '%s -> %s is going to an excluded destination' % (src, dst)\n",
    "                    inToOutD[src] += ct\n",
    "                    continue\n",
    "                assert dst in facDict, 'unknown dst %s in %s' % (dst, fnForMsg)\n",
    "                cleanedTbl[src][dst] = ct\n",
    "    return cleanedTbl, inToOutD, outToInD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tablesMatch(tbl1, tbl2):\n",
    "    if tbl1 is None:\n",
    "        if tbl2 is None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    elif tbl2 is None:\n",
    "        return False\n",
    "    else:\n",
    "        return {k: v for k, v in tbl1.items()} == {k: v for k, v in tbl2.items()}\n",
    "\n",
    "def tableNonNeg(tbl):\n",
    "    return all([all([v >= 0 for v in r.values()]) for r in tbl.values()])\n",
    "\n",
    "def writeYamlComment(f, comment=None):\n",
    "    if comment is not None:\n",
    "        lines = textwrap.wrap(comment)\n",
    "        for line in lines:\n",
    "            f.write('# %s\\n' % line)\n",
    "\n",
    "def checkAndMaybeRewrite(rawPath, valD, comment=None, createOnlyThese=None):\n",
    "    assert tableNonNeg(valD), 'Some elements of the given new value table are negative'\n",
    "    fn = pyrheautils.pathTranslate(rawPath)\n",
    "    if os.path.exists(fn):\n",
    "        with open(fn, 'rU') as f:\n",
    "            oldJSON = yaml.load(f)\n",
    "        if tablesMatch(oldJSON, valD):\n",
    "            print 'Old and new versions of %s match' % rawPath\n",
    "        else:\n",
    "            if createOnlyThese is None or rawPath in createOnlyThese:\n",
    "                print 'Old and new versions of %s differ' % rawPath\n",
    "                reply = raw_input('overwrite? [yN]')\n",
    "                if len(reply) == 1 and reply in 'yY':\n",
    "                    print 'overwriting old version of %s' % rawPath\n",
    "                    with open(fn, 'w') as f:\n",
    "                        writeYamlComment(f, comment)\n",
    "                        yaml.safe_dump(valD, f, default_flow_style=True, indent=4,\n",
    "                                       encoding='utf-8', width=130, explicit_start=True)\n",
    "                else:\n",
    "                    print 'old version of %s was NOT overwritten' % rawPath\n",
    "            else:\n",
    "                print 'did not create %s because it was not on the list to be created' % rawPath\n",
    "    else:\n",
    "        if createOnlyThese is None or rawPath in createOnlyThese:\n",
    "            print 'Writing %s because there is no old version' % rawPath\n",
    "            with open(fn, 'w') as f:\n",
    "                writeYamlComment(f, comment)\n",
    "                yaml.safe_dump(valD, f, default_flow_style=True, indent=4,\n",
    "                                encoding='utf-8', width=130, explicit_start=True)\n",
    "        else:\n",
    "            print '%s did not exist and was not created' % rawPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sumOfTableValues(tbl):\n",
    "    return sum([sum(rec.values()) for rec in tbl.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following block loads the model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "homeDir = '/home/welling/git/pyRHEA_github/src/sim'\n",
    "inputDict = tu.readModelInputs(os.path.join(homeDir, 'week_run_OC.yaml'))\n",
    "pyrheautils.prepPathTranslations(inputDict, homeDir=homeDir)\n",
    "print inputDict['facilityDirs']\n",
    "for dn in inputDict['facilityDirs']: print pyrheautils.pathTranslate(dn)\n",
    "facDict = tu.getFacDict(inputDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excludedFacDict = tu.parseFacilityData(pyrheautils.pathTranslate('$(MODELDIR)/facilityfacts_excluded'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a table of RHEA 1.0 -> RHEA 2.0 name changes\n",
    "obsoleteNameD = {'FDCT': 'FAIR', 'CCHS': 'SCNH', 'SJMC': 'SJNH', 'CMCS': 'CPNH'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the YAML constants for the transfer pattern implementations ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indirectConstantsFN = pyrheautils.pathTranslate('$(MODELDIR)/constants/indirecttransferdestination_constants.yaml')\n",
    "indirectSchemaFN = 'indirecttransferdestination_constants_schema.yaml'\n",
    "directConstantsFN = pyrheautils.pathTranslate('$(MODELDIR)/constants/transferbydrawwithreplacement_constants.yaml')\n",
    "directSchemaFN = 'transferbydrawwithreplacement_constants_schema.yaml'\n",
    "categoryDirectConstantsFN = pyrheautils.pathTranslate('$(MODELDIR)/constants/categorydrawwithreplacement_constants.yaml')\n",
    "categoryDirectSchemaFN = directSchemaFN\n",
    "communityConstantsFN = pyrheautils.pathTranslate('$(MODELDIR)/constants/community_constants.yaml')\n",
    "communitySchemaFN = 'community_constants_schema.yaml'\n",
    "indirectJSON = pyrheautils.importConstants(indirectConstantsFN, indirectSchemaFN)\n",
    "directJSON = pyrheautils.importConstants(directConstantsFN, directSchemaFN)\n",
    "categoryDirectJSON = pyrheautils.importConstants(categoryDirectConstantsFN, categoryDirectSchemaFN)\n",
    "communityConstantsJSON = pyrheautils.importConstants(communityConstantsFN, communitySchemaFN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the yaml tabular transfer data ##\n",
    "\n",
    "and remember their filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allNeededYamlTables = []\n",
    "\n",
    "indirectTbl = {}\n",
    "print 'loading indirect transfers'\n",
    "for fn in indirectJSON['transferFilePaths']:\n",
    "    indirectTbl = addTransfersToTable(fn, indirectJSON['transferFileSchema'], indirectTbl)\n",
    "    allNeededYamlTables.append(fn)\n",
    "\n",
    "directTbl = {}\n",
    "print 'loading direct transfers'\n",
    "for fn in directJSON['transferFilePaths']:\n",
    "    directTbl = addTransfersToTable(fn, indirectJSON['transferFileSchema'], directTbl)\n",
    "    allNeededYamlTables.append(fn)\n",
    "\n",
    "categoryDirectTbl = {}\n",
    "print 'loading category direct transfers'\n",
    "for fn in categoryDirectJSON['transferFilePaths']:\n",
    "    categoryDirectTbl = addTransfersToTable(fn, indirectJSON['transferFileSchema'], categoryDirectTbl)\n",
    "    allNeededYamlTables.append(fn)\n",
    "\n",
    "bypassIndirectTbl = {}\n",
    "print 'loading bypass indirect transfers'\n",
    "for fn in indirectJSON['bypassTransferFilePaths']:\n",
    "    bypassIndirectTbl = addTransfersToTable(fn, indirectJSON['transferFileSchema'], bypassIndirectTbl)\n",
    "    allNeededYamlTables.append(fn)\n",
    "\n",
    "# For the marginalized tables we only need to know filenames so the correct files can get created\n",
    "print 'noting some needed marginalized files'\n",
    "for fn in (communityConstantsJSON['srcToCategoryMapFilePaths']\n",
    "           + communityConstantsJSON['bypassCategoryMapFilePaths']):\n",
    "    allNeededYamlTables.append(fn)\n",
    "\n",
    "allNeededYamlTables = list(set(allNeededYamlTables))  # get rid of any duplicates\n",
    "allNeededYamlTables.sort()\n",
    "\n",
    "print 'Basic needed yaml tables:'\n",
    "for fn in allNeededYamlTables:\n",
    "    print '   %s' % fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This block generates a new YAML table giving transfer counts for the 'missing' patients ##\n",
    "\n",
    "The steps are:\n",
    "\n",
    "* load the new and old versions of the CSV files\n",
    "* check for any extraneous changes in the transfer table data\n",
    "* check the new transfer table data against the current YAML version of that data\n",
    "* put the new data on 'missing' patients in a new YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(pyrheautils.pathTranslate('$(MODELDIR)/OC_Direct_Transfer_Matrices_for_RHEA_2.0_-_Adult_Only_-_09-15-2017_FINAL_HOSP-NH.csv')) as f:\n",
    "    oldKeys, oldRecs = csv_tools.parseCSV(f)\n",
    "print oldKeys\n",
    "with open(pyrheautils.pathTranslate('$(MODELDIR)/OC_Direct_Transfer_Matrices_for_RHEA_2.0_-_Adult_Only_-_06-29-2018_FINAL__missing_admit_update_HOSP-NH.csv')) as f:\n",
    "    newKeys, newRecs = csv_tools.parseCSV(f)\n",
    "print newKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trimmedNewRecs = []\n",
    "missingRec = {}\n",
    "lblKey = '\"Hospital-NH Transfers 2 Years of Data Averaged (2013-2014)\"'\n",
    "missingRec[lblKey] = 'MISSING_SRC'\n",
    "for rec in newRecs:\n",
    "    rowLbl = rec[lblKey]\n",
    "    if rowLbl.startswith('MISSING'):\n",
    "        for key, val in rec.items():\n",
    "            if key != lblKey:\n",
    "                if key in missingRec:\n",
    "                    missingRec[key] += val\n",
    "                else:\n",
    "                    missingRec[key] = val\n",
    "    else:\n",
    "        trimmedNewRecs.append(rec)\n",
    "trimmedNewRecs.append(missingRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lblKey = '\"Hospital-NH Transfers 2 Years of Data Averaged (2013-2014)\"'\n",
    "newD = recsToDict(trimmedNewRecs, lblKey)\n",
    "print newD.keys()\n",
    "\n",
    "lblKey = '\"Transfers 2 Years of Data Averaged (2013-2014)\"'\n",
    "oldD = recsToDict(oldRecs, lblKey)\n",
    "print oldD.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell checks the new direct transfer csv against the old (pre-missing-data) version, and checks the new version against the corresponding YAML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, rec in oldD.items():\n",
    "    assert key in newD, 'Missing key %s' % key\n",
    "    assert rec == newD[key], 'rec mismatch (%s vs %s)' % (rec, newD[key])\n",
    "    #print '%s OK' % key\n",
    "for key, rec in newD.items():\n",
    "    if key == 'MISSING_SRC':\n",
    "        continue\n",
    "    assert key in oldD, 'Missing key %s' % key\n",
    "    assert rec == oldD[key], 'rec mismatch (%s vs %s)' % (rec, oldD[key])\n",
    "    if key in directTbl:\n",
    "        commonDst = []\n",
    "        for dst, ct in rec.items():\n",
    "            if dst in directTbl[key]:\n",
    "                assert ct == directTbl[key][dst], 'Vals for %s %s do not match: %s vs %s' % (key, dst, ct, directTbl[key][dst])\n",
    "                commonDst.append(dst)\n",
    "        #print '%s common destinations: %s' % (key, commonDst)\n",
    "    print '%s OK; ' % key,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missingD = {}\n",
    "for dst, vStr in newD['MISSING_SRC'].items():\n",
    "    try:\n",
    "        v = float(vStr)\n",
    "        missingD[dst] = v\n",
    "    except ValueError:\n",
    "        print 'excluding %s %s' % (dst, vStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totMissingPerYear = sum(missingD.values())\n",
    "print 'total missing: ', totMissingPerYear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan the existing yaml files without remembering them ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for fn in (indirectJSON['transferFilePaths'] + directJSON['transferFilePaths']\n",
    "           + categoryDirectJSON['transferFilePaths'] + ['$(MODELDIR)/com_to_fac_missing_patients_indirect.yaml']):\n",
    "    print '----------------'\n",
    "    tbl = addTransfersToTable(fn, indirectJSON['transferFileSchema'])\n",
    "    tbl, inToOutD, outToInD = cleanTransferTbl(tbl, fn, obsoleteNameD)\n",
    "    cleanTot = sumOfTableValues(tbl)\n",
    "    inToOutTot = sum(inToOutD.values())\n",
    "    outToInTot = sum(outToInD.values())\n",
    "    print '%s: %s valid, %s in-to-out, %s out-to-in' % (fn, cleanTot, inToOutTot, outToInTot)\n",
    "    print 'inToOutD: %s' % {a: b for a, b in inToOutD.items()}\n",
    "    print 'outToInD: %s' % {a: b for a, b in outToInD.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic To and From Excluded Sites ##\n",
    "\n",
    "If an excluded site appears as a source in direct_transfer_counts, any patients flowing from that site to an included site (out-to-in) appear at the destination site from outside the system and thus should be 'missing source' patients.  That is, functionally they add to com_to_fac_missing_patients_indirect.yaml\n",
    "\n",
    "If an excluded site appears as a destination direct_transfer_counts, those patients are in-to-out and should appear as additional flow back to the community.  Ideally they would be removed from facDict[loc][totalTransfersOut] so that the go-home fraction calculated for the fac would increase appropriately.\n",
    "\n",
    "If an excluded site appears as a source in hosp_indirect_transfer_counts or nh_readmit_transfer_counts, the out-to-in patient is still transferred from community to some in-simulation facility but the source location for that patient becomes unknown.  This would essentially be an addition to com_to_fac_marginalized_indirect.yaml .\n",
    "\n",
    "If an excluded site appears as a destination in hosp_indirect_transfer_counts or nh_readmit_transfer_counts, the patient would appear not to have returned to the medical system from the community.  Thus these patients would subtract from com_to_fac_marginalized_indirect.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationale for Normalization ##\n",
    "\n",
    "For the indirect transfer tables, normalization is performed independently for each pair of source and destination tier, across all destinations matching that tier.  So as long as the source or tier is unique to a given input file, that input file can have any normalization.\n",
    "\n",
    "We are concerned with adding the 'MISSING_SRC' data, which is replicated identically across all sources.  So for NHs the normalization must match other NH sources, and for non-NHs it must match hosp_indirect_transfer_counts.\n",
    "\n",
    "| src tier  | dest tier  | count  | fname  | notes |\n",
    "|---|---|---|---|---|\n",
    "| non-NH  | non-NH  | 56863  | hosp_indirect_transfer_counts  | real counts over a year |\n",
    "| any  | NH  | 7965.01 | com_to_fac_missing_patients_indirect  | each src and tier is a real count over a year |\n",
    "| NH  | non-NH  | 76 x 1.0  | nh_readmit_fake_transfer_counts  | do we know the size of this channel? |\n",
    "\n",
    "The only channel that delivers patients to the NH tier is com_to_fac_missing_patients_indirect, so that channel can have its own normalization.  We do not know the total counts/year in the nh_readmit_fake_transfer_counts channel, but because its combination of src and dest tier are unique it will be independently normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and remember some principle files ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = pyrheautils.pathTranslate('$(MODELDIR)/hosp_indirect_transfer_counts.yaml')\n",
    "rawHospIndirectTransfers = addTransfersToTable(fn, indirectJSON['transferFileSchema'])\n",
    "cleanHospIndirectTransfers, hospIndirectInToOutD, hospIndirectOutToInD = cleanTransferTbl(rawHospIndirectTransfers,\n",
    "                                                                                          fn, obsoleteNameD)\n",
    "fn = pyrheautils.pathTranslate('$(MODELDIR)/nh_readmit_transfer_counts.yaml')\n",
    "rawNHReadmitTransfers = addTransfersToTable(fn, indirectJSON['transferFileSchema'])\n",
    "cleanNHReadmitTransfers, nhReadmitInToOutD, nhReadmitOutToInD = cleanTransferTbl(rawNHReadmitTransfers,\n",
    "                                                                                 fn, obsoleteNameD)\n",
    "fn = pyrheautils.pathTranslate('$(MODELDIR)/direct_transfer_counts.yaml')\n",
    "rawDirectTransfers = addTransfersToTable(fn, indirectJSON['transferFileSchema'])\n",
    "cleanDirectTransfers, directInToOutD, directOutToInD = cleanTransferTbl(rawDirectTransfers,\n",
    "                                                                        fn, obsoleteNameD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the missing data in the same format ##\n",
    "\n",
    "Note that we are regenerating the missing data from the newD CSV records rather than using any existing yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cleanMissingTransfers, missingInToOutD, missingOutToInD = cleanTransferTbl({'COMMUNITY': missingD},\n",
    "                                                                          'noRealFile', obsoleteNameD)\n",
    "print 'missingInToOut: %s' % {k:v for k,v in missingInToOutD.values()}\n",
    "print 'missingOutToIn: %s' % {k:v for k,v in missingOutToInD.values()}\n",
    "print cleanMissingTransfers.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables We Have, And What To Do With Them ##\n",
    "\n",
    "| src tier  | dest tier  | via home? | name | notes |\n",
    "|-----------|------------|-----------|------|-------|\n",
    "| any | any  |  no  | cleanDirectTransfers | |\n",
    "| non-NH | non-NH | yes | cleanHospIndirectTransfers | |\n",
    "| | |  | cleanNHReadmitTransfers | empty |\n",
    "| NH | non-NH | yes | nh_readmit_fake_transfer_counts | made from hosp_indirect etc below |\n",
    "| None | any | yes | com_to_fac_marginalized_indirect | made from hosp_indirect etc below |\n",
    "| NH | non-NH | yes | nh_to_cat_fake_indirect | made from cleanHospIndirectTransfers |\n",
    "\n",
    "* directInToOutD : This would be discharges to community.  If we regenerate direct_transfer_counts from cleanDirectTransfers we could then regenerate the facility files with updated discharge info.  facility_data_manipulator.ipynb can reconstruct those, but it depends on all the .yaml files this notebook is producing, including the marginalized versions.\n",
    "\n",
    "* directOutToInD : This would be flow from community to facilities.  It would increase the admission counts of the destination facilities, and we would have to increase the community get-sick rate to compensate.\n",
    "\n",
    "* cleanMissingTransfers : This would be flow from community to facilities.  Can we just merge it with directOutToInD?\n",
    "\n",
    "* cleanHospIndirectTransfers + cleanNHReadmitTransfers :\n",
    "\n",
    "* hospIndirectOutToInD : empty. If there were any, they would look like admissions with history None.\n",
    "\n",
    "* hospIndirectInToOutD : entries look like people who do not return to the health care system\n",
    "\n",
    "* cleanNHReadmitTransfers : empty\n",
    "\n",
    "* nhReadmitOutToInD: empty\n",
    "\n",
    "* nhReadmitInToOutD: empty\n",
    "\n",
    "After we have these, we have to marginalize destinations to facility categories to provide input for community getStatusChangeTree.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check main yaml files against internal representation and optionally rewrite them ##\n",
    "\n",
    "This step will finally create the com_to_fac_missing_patients_indirect table if it does not already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "checkAndMaybeRewrite('$(MODELDIR)/direct_transfer_counts.yaml', cleanDirectTransfers,\n",
    "                    createOnlyThese=allNeededYamlTables)\n",
    "checkAndMaybeRewrite('$(MODELDIR)/hosp_indirect_transfer_counts.yaml', cleanHospIndirectTransfers,\n",
    "                    createOnlyThese=allNeededYamlTables)\n",
    "checkAndMaybeRewrite('$(MODELDIR)/nh_readmit_transfer_counts.yaml', cleanNHReadmitTransfers,\n",
    "                    createOnlyThese=allNeededYamlTables)\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_fac_missing_patients_indirect.yaml', cleanMissingTransfers,\n",
    "                    comment=(\"This file was generated from the MISSING entries of the\"\n",
    "                            \"direct transfer table\"),\n",
    "                    createOnlyThese=allNeededYamlTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Irrespective of their history, some fraction of newly sick COM patients need to follow missingD.  \n",
    "# Respecting their history, some need to follow hosp_indirect_transfer_counts and nh_readmit_transfer_counts.\n",
    "cleanMissing = {fac: cleanMissingTransfers['COMMUNITY'].copy() for fac in facDict\n",
    "               if facDict[fac]['category'] != 'COMMUNITY'}\n",
    "checkAndMaybeRewrite('$(MODELDIR)/missing_indirect_transfer_counts.yaml', cleanMissing,\n",
    "                    comment=(\"This file was generated by taking the 'missing' arrival count for\"\n",
    "                            \" all facilities as incoming transfers and replicating the resulting\"\n",
    "                            \" transfers across all facilities\"),\n",
    "                    createOnlyThese=allNeededYamlTables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need to provide a table of indirect transfer destination categories originating from NHs,\n",
    "# but that data is not included in the available tables.  A fair solution is probably to use\n",
    "# the indirect transfers from hospitals averaged over hospitals, and apply it to all NHs.\n",
    "catCtD = defaultdict(lambda: 0)\n",
    "allSrcTbl = defaultdict(lambda: 0)\n",
    "srcCatCtD = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for srcName, rec in cleanHospIndirectTransfers.items():\n",
    "    for dstName, ct in rec.items():\n",
    "        dstCategory = facDict[dstName]['category']\n",
    "        catCtD[dstCategory] += float(ct)\n",
    "        allSrcTbl[dstName] += float(ct)\n",
    "        srcCatCtD[srcName][dstCategory] += float(ct)\n",
    "tot = sum(catCtD.values())\n",
    "print tot\n",
    "netRec = {cat: float(ct)/float(tot) for cat, ct in catCtD.items()}\n",
    "print netRec\n",
    "fakeD = {}\n",
    "for abbrev in facDict:\n",
    "    if facDict[abbrev]['category'] == 'NURSINGHOME':\n",
    "        fakeD[abbrev] = netRec.copy()\n",
    "checkAndMaybeRewrite('$(MODELDIR)/nh_to_cat_fake_indirect.yaml', fakeD,\n",
    "                    comment=(\"This table was generated by finding the overall fraction of\"\n",
    "                            \" indirect transfers originating from any HOSP or LTAC to\"\n",
    "                            \" facilities of the given category and replicating that ratio\"\n",
    "                            \" for all NURSINGHOMES.\"),\n",
    "                    createOnlyThese=allNeededYamlTables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We need a table of missing transfer information marginalized across destination categories\n",
    "# to serve as the upstream end for the com_to_fac_missing_patients_indirect table.\n",
    "tmpD = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for srcName, rec in cleanMissingTransfers.items():\n",
    "    for dstName, ct in rec.items():\n",
    "        dstCategory = facDict[dstName]['category']\n",
    "        tmpD[srcName][dstCategory] += float(ct)\n",
    "        #print '%s %s' % (srcName, dstCategory)\n",
    "comCatMissingD = {}\n",
    "for srcName, rec in tmpD.items():\n",
    "    tot = sum(rec.values())\n",
    "    comCatMissingD[srcName] = {}\n",
    "    for dstCat, ct in rec.items():\n",
    "        comCatMissingD[srcName][dstCat] = float(ct)/float(tot)\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_cat_missing_patients_indirect.yaml', comCatMissingD,\n",
    "                    comment=(\"This table was generated by summing com_to_fac_missing_patients_indirect\"\n",
    "                            \" over destination category\"),\n",
    "                    createOnlyThese=allNeededYamlTables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We also need a table mapping from NHs to destination HOSPs to substitute for the missing information\n",
    "# on indirect transfers originating from NHs.  This is essentially the second half of the routing\n",
    "# provided by nh_to_cat_fake_indirect.yaml created above.\n",
    "totCt = sum(allSrcTbl.values())\n",
    "normAllSrcTbl = {dst: float(ct)/float(totCt) for dst, ct in allSrcTbl.iteritems()}\n",
    "fakeD = {}\n",
    "for abbrev in facDict:\n",
    "    if facDict[abbrev]['category'] == 'NURSINGHOME':\n",
    "        fakeD[abbrev] = {key:val for key,val in normAllSrcTbl.items()}  # get rid of defaultdict\n",
    "checkAndMaybeRewrite('$(MODELDIR)/nh_readmit_fake_transfer_counts.yaml', fakeD,\n",
    "                    comment=(\"This was generated by summing hosp_indirect_transfer_counts.yaml\"\n",
    "                            \" and nh_readmit_transfer_counts.yaml over source locations and\"\n",
    "                            \" normalizing, then replicating the resulting map for all NHs\"),\n",
    "                    createOnlyThese=allNeededYamlTables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normSrcCatCtD = {}\n",
    "for src, catD in srcCatCtD.items():\n",
    "    tot = sum(catD.values())\n",
    "    normCatCtD = {cat: ct/tot for cat, ct in catD.items()}\n",
    "    normSrcCatCtD[src] = normCatCtD\n",
    "checkAndMaybeRewrite('$(MODELDIR)/fac_to_cat_marginalized_indirect.yaml', normSrcCatCtD,\n",
    "                    comment=(\"This was generated by summing hosp_indirect_transfer_counts.yaml\"\n",
    "                            \" and nh_readmit_transfer_counts.yaml across destination facility\"\n",
    "                            \" by category and then normalizing the resulting counts by source\"\n",
    "                            \" facility\"),\n",
    "                    createOnlyThese=allNeededYamlTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print srcCatCtD['SJUD']\n",
    "print normSrcCatCtD['SJUD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oD = {}\n",
    "oD['COMMUNITY'] = {key:val for key,val in allSrcTbl.items()}  # get rid of defaultdict\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_fac_indirect.yaml', oD,\n",
    "                    comment=(\"This was generated by summing hosp_indirect_transfer_counts.yaml\"\n",
    "                            \" and nh_readmit_transfer_counts.yaml over source locations\"),\n",
    "                    createOnlyThese=allNeededYamlTables)\n",
    "oD = {}\n",
    "oD['COMMUNITY'] = {key:val for key,val in normAllSrcTbl.items()}  # get rid of defaultdict\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_fac_marginalized_indirect.yaml', oD,\n",
    "                    comment=(\"This was generated by summing hosp_indirect_transfer_counts.yaml\"\n",
    "                            \" and nh_readmit_transfer_counts.yaml over source locations and\"\n",
    "                            \" normalizing\"),\n",
    "                    createOnlyThese=allNeededYamlTables)\n",
    "comToFacMarginalizedIndirectD = oD  # turns out we need it later\n",
    "#kL = allSrcTbl.keys()[:]\n",
    "#kL.sort()\n",
    "#for k in kL:\n",
    "    #print '%s: %s' % (k, allSrcTbl[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goHomeRec = {}\n",
    "for fac in [f for f in facDict if facDict[f]['category'] != 'COMMUNITY']:\n",
    "    nDischarged = facDict[fac]['totalDischarges']['value']\n",
    "    nTransOut = sum(srcCatCtD[fac].values())\n",
    "    goHomeRec[fac] = nDischarged - nTransOut\n",
    "goHomeD= {'COMMUNITY': goHomeRec}\n",
    "cleanGoHomeD, goHomeInToOutD, goHomeOutToInD = cleanTransferTbl(goHomeD, 'NoRealFile', obsoleteNameD)\n",
    "print 'goHomeInToOutD: %s' % {k: v for k, v in goHomeInToOutD.items()}\n",
    "print 'goHomeOutToInD: %s' % {k: v for k, v in goHomeOutToInD.items()}\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_fac_from_discharge_rate.yaml', cleanGoHomeD,\n",
    "                    comment=(\"The flow given here for each facility is the total discharge\"\n",
    "                            \" rate for the facility minus total direct transfers out of the\"\n",
    "                            \" facility\"),\n",
    "                    createOnlyThese=allNeededYamlTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'sum of cleanGoHomeD: ', sumOfTableValues(cleanGoHomeD)\n",
    "print 'sum of cleanHospIndirectTransfers: ', sumOfTableValues(cleanHospIndirectTransfers)\n",
    "print 'sum of cleanNHReadmitTransfers: ', sumOfTableValues(cleanNHReadmitTransfers)\n",
    "print 'sum of cleanMissingTransfers: ', sumOfTableValues(cleanMissingTransfers)\n",
    "totComPop = 0\n",
    "for fac, rec in facDict.items():\n",
    "    if rec['category'] == 'COMMUNITY':\n",
    "        totComPop += rec['meanPop']['value']\n",
    "print 'total community population: ', totComPop\n",
    "oldRate = 365*1.925e-4*totComPop\n",
    "print 'old rate: ', oldRate\n",
    "print sumOfTableValues(cleanGoHomeD) - oldRate\n",
    "d = defaultdict(lambda: 0)\n",
    "for src, ct in cleanGoHomeD['COMMUNITY'].items():\n",
    "    if src in facDict:\n",
    "        d[facDict[src]['category']] += ct\n",
    "d = {k:v for k,v in d.iteritems()}\n",
    "print 'cleanGoHomeD categories: ', d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deltaD = {}\n",
    "aveD = {}\n",
    "itD = {}\n",
    "dtD = {}\n",
    "print sum(cleanHospIndirectTransfers['SJUD'].values())\n",
    "for fac, rec in facDict.items():\n",
    "    if facDict[fac]['category'] != 'COMMUNITY':\n",
    "        nDischarged = facDict[fac]['totalDischarges']['value']\n",
    "        nDirectTrans = sum([r['count']['value'] for r in facDict[fac]['totalTransfersOut']])\n",
    "        nIndirectTrans = (sum(cleanHospIndirectTransfers[fac].values())\n",
    "                          if fac in cleanHospIndirectTransfers else 0.0)\n",
    "        nAdmitted = facDict[fac]['totalAdmissions']['value']\n",
    "        deltaD[fac] = nDischarged - nAdmitted\n",
    "        aveD[fac] = 0.5*(nDischarged + nAdmitted)\n",
    "        itD[fac] = nIndirectTrans\n",
    "        dtD[fac] = nDirectTrans\n",
    "\n",
    "def printTbl(facL = None):\n",
    "    if facL is None:\n",
    "        facL = [fac for fac in facDict if facDict[fac]['category'] != 'COMMUNITY']\n",
    "        facL.sort()\n",
    "    for fac in facL:\n",
    "        dv = deltaD[fac] if fac in deltaD else 0.0\n",
    "        av = aveD[fac] if fac in aveD else 0.0\n",
    "        itv = itD[fac] if fac in itD else 0.0 \n",
    "        dtv = dtD[fac] if fac in dtD else 0.0\n",
    "        mv = cleanMissingTransfers['COMMUNITY'][fac] if fac in cleanMissingTransfers['COMMUNITY'] else 0.0\n",
    "        print '%s (%s) %s %s %s %s %s' % (fac, facDict[fac]['category'], dv, av, itv, dtv, mv)\n",
    "#printTbl()\n",
    "printTbl(['SJUD', 'PACI'])\n",
    "print cleanMissingTransfers['COMMUNITY']['PACI']\n",
    "print facDict['PACI']['totalTransfersIn']['value']\n",
    "print facDict['PACI']['totalDischarges']['value']\n",
    "print facDict['PACI']['totalDischarges']['value'] - facDict['PACI']['totalTransfersIn']['value']\n",
    "tot = 0.0\n",
    "for fac in facDict:\n",
    "    if facDict[fac]['category'] == 'HOSPITAL':\n",
    "        v1 = cleanMissingTransfers['COMMUNITY'][fac] if fac in cleanMissingTransfers['COMMUNITY'] else 0.0\n",
    "        #v2 = facDict[fac]['totalDischarges']['value'] - (facDict[fac]['totalTransfersIn']['value'] + allSrcTbl[fac])\n",
    "        v2 = facDict[fac]['totalDischarges']['value']\n",
    "        v3 = sum(r['count']['value'] for r in facDict[fac]['totalTransfersOut'])\n",
    "        v4 = sum(cleanDirectTransfers[fac].values())\n",
    "        v5 = facDict[fac]['totalTransfersIn']['value']\n",
    "        v6 = 0.0\n",
    "        for src in cleanDirectTransfers:\n",
    "            if fac in cleanDirectTransfers[src]:\n",
    "                v6 += cleanDirectTransfers[src][fac]\n",
    "        #print fac, v1, v2, v3, v4, sum(srcCatCtD[fac].values())\n",
    "        print fac, v5, v6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleanGoHomeD is (all discharges - HOSP_indirect), so it represents counts that are not expected to return.\n",
    "\n",
    "Balanced numbers: everyone gets (totalDischarges - totalTransfersIn) regardless of source\n",
    "\n",
    "Obeying indirect transfer matrix: everyone gets sum(cleanIndirect[?][dst=fac]) + cleanGoHomeD[fac]\n",
    "\n",
    "actualMissing = (balanced numbers) - (obeying indirect transfer matrix)\n",
    "\n",
    "I can use \n",
    "```\n",
    "sum(cleanDirectTransfers[fac].values())\n",
    "```\n",
    "in lieu of \n",
    "```\n",
    "sum(r['count']['value'] for r in facDict[fac]['totalTransfersOut'])\n",
    "```\n",
    "to get the total number of direct transfers out\n",
    "\n",
    "I can use\n",
    "```\n",
    "        for src in cleanDirectTransfers:\n",
    "            if fac in cleanDirectTransfers[src]:\n",
    "                v6 += cleanDirectTransfers[src][fac]\n",
    "```\n",
    "in lieu of\n",
    "```\n",
    "    facDict[fac]['totalTransfersIn']['value']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "balancedFromCommunityD = {}\n",
    "for fac in facDict:\n",
    "    if facDict[fac]['category'] == 'COMMUNITY':\n",
    "        continue\n",
    "    nOut = facDict[fac]['totalDischarges']['value']\n",
    "    nInByDirectTransfer = 0.0\n",
    "    for src in cleanDirectTransfers:\n",
    "        if fac in cleanDirectTransfers[src]:\n",
    "            nInByDirectTransfer += cleanDirectTransfers[src][fac]\n",
    "    nFromCommunity = nOut - nInByDirectTransfer\n",
    "    #print fac, nInByDirectTransfer, nOut, nFromCommunity\n",
    "    balancedFromCommunityD[fac] = nFromCommunity\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_fac_to_balance_discharges.yaml',\n",
    "                     {'COMMUNITY': balancedFromCommunityD},\n",
    "                    comment=(\"The flow given here is the discharge rate minus the\"\n",
    "                            \"total direct transfers arriving at the facility\"),\n",
    "                    createOnlyThese=allNeededYamlTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "balancedFromCommunityToCatD = defaultdict(lambda: 0.0)\n",
    "for fac, ct in balancedFromCommunityD.items():\n",
    "    balancedFromCommunityToCatD[facDict[fac]['category']] += ct\n",
    "balancedFromCommunityToCatD = {k: v for k, v in balancedFromCommunityToCatD.iteritems()}\n",
    "#print balancedFromCommunityToCatD\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_cat_to_balance_discharges.yaml',\n",
    "                    {'COMMUNITY': balancedFromCommunityToCatD},\n",
    "                    comment=('The flow given here is com_to_fac_to_balance_discharges.yaml'\n",
    "                            ' marginalized over destination categories'),\n",
    "                    createOnlyThese=allNeededYamlTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indirectFromCommunityD = {}\n",
    "for fac in facDict:\n",
    "    if facDict[fac]['category'] == 'COMMUNITY':\n",
    "        continue\n",
    "    nFromIndirect = 0.0\n",
    "    for src in cleanHospIndirectTransfers:\n",
    "        if fac in cleanHospIndirectTransfers[src]:\n",
    "            nFromIndirect += cleanHospIndirectTransfers[src][fac]\n",
    "    indirectFromCommunityD[fac] = nFromIndirect\n",
    "    #if facDict[fac]['category'] == 'NURSINGHOME':\n",
    "    #    print fac, nFromIndirect, balancedFromCommunityD[fac], (cleanMissingTransfers['COMMUNITY'][fac] \n",
    "    #                                                     if fac in cleanMissingTransfers['COMMUNITY'] else 0.0)\n",
    "realDeficitD = {}\n",
    "for fac in balancedFromCommunityD:\n",
    "    nFromCommunity = balancedFromCommunityD[fac]\n",
    "    nFromIndirect = indirectFromCommunityD[fac] if fac in indirectFromCommunityD else 0.0\n",
    "    realDeficitD[fac] = nFromCommunity - nFromIndirect\n",
    "    #if facDict[fac]['category'] != 'NURSINGHOME':\n",
    "    #    print (fac, facDict[fac]['totalAdmissions']['value'], facDict[fac]['totalDischarges']['value'],\n",
    "    #          realDeficitD[fac], \n",
    "    #           (cleanMissingTransfers['COMMUNITY'][fac] if fac in cleanMissingTransfers['COMMUNITY'] else 0.0))\n",
    "fac = 'HOAG'\n",
    "nInByDirectTransfer = 0.0\n",
    "for src in cleanDirectTransfers:\n",
    "    if fac in cleanDirectTransfers[src]:\n",
    "        nInByDirectTransfer += cleanDirectTransfers[src][fac]\n",
    "nOut = facDict[fac]['totalDischarges']['value']\n",
    "nFromIndirect = indirectFromCommunityD[fac] if fac in indirectFromCommunityD else 0.0\n",
    "realDeficit = realDeficitD[fac]\n",
    "print fac, nOut, nInByDirectTransfer, balancedFromCommunityD[fac], nFromIndirect, realDeficit\n",
    "# realDeficit here is the number of thaws which go to fac *beyond* those necessary to cover indirect transfers\n",
    "# Total thaws going to this fac should be nFromIndirect + realDeficit == balancedFromCommunity[fac]\n",
    "# Total thaws should equal sum(balancedFromCommunity.values())\n",
    "# Total thaws excluding 'corrected missing' should be sum(admissions - directTransfersIn)\n",
    "#                                                   = sum(admissions) - sum(cleanDirectTransfers)\n",
    "totPerYear = sum(balancedFromCommunityD.values())\n",
    "totRate = totPerYear/(365.0 * totComPop)\n",
    "print totPerYear, totRate\n",
    "totAdmissions = 0.0\n",
    "for fac in facDict:\n",
    "    if facDict[fac]['category'] != 'COMMUNITY':\n",
    "        totAdmissions += facDict[fac]['totalAdmissions']['value']\n",
    "nonBypassPerYear = totAdmissions - sumOfTableValues(cleanDirectTransfers)\n",
    "print nonBypassPerYear\n",
    "bypassFrac = (totPerYear - nonBypassPerYear)/totPerYear\n",
    "print 'total thaws per year: ', totPerYear\n",
    "print 'base thaw rate is: ', totRate\n",
    "print 'bypass fraction is: ', bypassFrac\n",
    "\n",
    "# total thaws going to fac should be balancedFromCommunityD[fac]\n",
    "# total thaws which actually go there are totPerYear * fraction to the given fac\n",
    "# the best estimate of fraction to the given fac is probably from com_to_fac_marginalized_indirect\n",
    "trueMissingD = {}\n",
    "for fac in facDict:\n",
    "    if facDict[fac]['category'] != 'COMMUNITY':\n",
    "        nPerYear = (totPerYear * comToFacMarginalizedIndirectD['COMMUNITY'][fac]\n",
    "                    if fac in comToFacMarginalizedIndirectD['COMMUNITY'] else 0.0)\n",
    "        trueMissingD[fac] = (balancedFromCommunityD[fac] - nPerYear)\n",
    "if tableNonNeg({'COMMUNITY': trueMissingD}):\n",
    "    checkAndMaybeRewrite('$(MODELDIR)/com_to_fac_true_missing.yaml',\n",
    "                        {'COMMUNITY': trueMissingD},\n",
    "                        comment=(\"This table gives an estimate of the number of discharges not\"\n",
    "                                \" accounted for by direct transfers, indirect transfers, and\"\n",
    "                                \" admissions from the community which are neither direct nor indirect\"),\n",
    "                        createOnlyThese=allNeededYamlTables)\n",
    "else:\n",
    "    print 'This idea fails because discharges may be less than admissions due to sampling error'\n",
    "print comToFacMarginalizedIndirectD['COMMUNITY']['HOAG']\n",
    "print (totPerYear * comToFacMarginalizedIndirectD['COMMUNITY']['HOAG'])\n",
    "print balancedFromCommunityD['HOAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "toCatD = defaultdict(lambda: 0)\n",
    "for fac, ct in cleanGoHomeD['COMMUNITY'].items():\n",
    "    toCatD[facDict[fac]['category']] += ct\n",
    "comToCatD = {'COMMUNITY': {k: v for k, v in toCatD.items()}}\n",
    "checkAndMaybeRewrite('$(MODELDIR)/com_to_cat_from_discharge_rate.yaml', comToCatD,\n",
    "                    comment=(\"These values were generated by summing com_to_fac_from_discharge_rate.yaml\"\n",
    "                            \" by destination category\"),\n",
    "                    createOnlyThese=allNeededYamlTables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cleanHospIndirectTransfers.keys()\n",
    "print cleanNHReadmitTransfers.keys()\n",
    "print cleanMissing.keys()\n",
    "print [facDict[fac]['category'] for fac in cleanMissing.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
